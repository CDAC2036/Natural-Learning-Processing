{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Administrator.DAI-PC2\\AppData\\Local\\Temp\\ipykernel_25376\\345950967.py\", line 19, in <module>\n",
      "    new_data = tfidf.fit_transform(X)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1389, in fit_transform\n",
      "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line None, in _count_vocab\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
    "df=pd.read_csv('research-papers.csv')\n",
    "X=df['Summary']\n",
    "\n",
    "X.apply(word_tokenize)\n",
    "new_data = tfidf.fit_transform(X)\n",
    "X = pd.DataFrame(index=range(0,len(X)), columns=tfidf.get_feature_names_out(), data=new_data.toarray())\n",
    "X[0]\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(df['Primary Category'])\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(X)\n",
    "# seq = tokenizer.texts_to_sequences(X)\n",
    "# X = pad_sequences(seq, padding='post')\n",
    "# print(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=24, stratify = y)\n",
    "# knn = KNeighborsClassifier(n_neighbors=6)\n",
    "# knn.fit(X_train, y_train)\n",
    "# y_pred = knn.predict(X_test)\n",
    "# y_pred_prob = knn.predict_proba(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "\n",
    "# print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n",
    "# print('Log Loss: ',log_loss(y_test,y_pred_prob))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
